{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "获取数据集并分析"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from motifcluster import clustering as mccl\n",
    "from motifcluster import motifadjacency as mcmo\n",
    "from motifcluster import utils as mcut\n",
    "import torch_geometric"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n",
      "train_data.edge_label:tensor([1., 1., 1.,  ..., 1., 1., 1.])\n",
      "train_data.edge_label_index:tensor([[ 136, 1073, 1701,  ...,  284, 1902,   97],\n",
      "        [ 831, 2163, 1858,  ..., 2225, 1904, 1353]])\n",
      "Data(x=[2708, 1433], edge_index=[2, 8976], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], edge_weight=[8976], edge_label=[526], edge_label_index=[2, 526])\n",
      "Data(x=[2708, 1433], edge_index=[2, 9502], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], edge_weight=[9502], edge_label=[1054], edge_label_index=[2, 1054])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.seed import seed_everything\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "\n",
    "seed_everything(123)\n",
    "\n",
    "dataset = Planetoid('dataset','Cora',transform=T.NormalizeFeatures())\n",
    "data = dataset[0]\n",
    "# 不再使用\n",
    "# data.train_mask = data.val_mask = data.test_mask = data.y = None\n",
    "\n",
    "print(data)\n",
    "\n",
    "# 加入mam\n",
    "# 使用MAM\n",
    "adj = data.edge_index\n",
    "adj = torch_geometric.utils.to_scipy_sparse_matrix(data.edge_index)\n",
    "mam = mcmo.build_motif_adjacency_matrix(adj,motif_name='M4',motif_type='func',mam_method='sparse',mam_weight_type='product')\n",
    "# 加上原邻接矩阵与边权重\n",
    "inte_adj = adj + mam\n",
    "mam_edge_index,mam_edge_weight = torch_geometric.utils.from_scipy_sparse_matrix(inte_adj)\n",
    "data.edge_index = mam_edge_index\n",
    "data.edge_weight = mam_edge_weight\n",
    "\n",
    "# 对边集进行分割\n",
    "split = T.RandomLinkSplit(is_undirected=True,add_negative_train_samples=False,num_val=0.05,num_test=0.1,neg_sampling_ratio=1.0)\n",
    "train_data,val_data,test_data = split(data)\n",
    "print(f'train_data.edge_label:{train_data.edge_label}\\ntrain_data.edge_label_index:{train_data.edge_label_index}')\n",
    "print(val_data)\n",
    "print(test_data)\n",
    "\n",
    "# 采样负样本边\n",
    "# data = train_test_split_edges(data)\n",
    "# train_pos_edge_index = data.train_pos_edge_index\n",
    "# for key in data.keys:\n",
    "#     print(key,getattr(data,key).shape)\n",
    "#     print(key,getattr(data,key))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "构造边预测神经网咯"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self,in_channels,out_channels):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels,128)\n",
    "        self.conv2 = GCNConv(128,out_channels)\n",
    "\n",
    "    # 编码：节点表征生成\n",
    "    # 使用边权重\n",
    "    def encode(self,x,edge_index,edge_weight):\n",
    "        x = self.conv1(x,edge_index,edge_weight)\n",
    "        x = x.relu()\n",
    "        return self.conv2(x,edge_index,edge_weight)\n",
    "\n",
    "    # 未加边权重\n",
    "    # def encode(self,x,edge_index):\n",
    "    #     x = self.conv1(x,edge_index)\n",
    "    #     x = x.relu()\n",
    "    #     return self.conv2(x,edge_index)\n",
    "\n",
    "    # 解码：根据边两端节点的表征生成边为真的概率\n",
    "    def decode(self,z,edge_label_index):\n",
    "        # 按倒数第一维来cat\n",
    "        return (z[edge_label_index[0]]*z[edge_label_index[1]]).sum(dim=-1)\n",
    "\n",
    "    # 推理阶段：对所有节点预测边存在的概率\n",
    "    def decode_all(self,z):\n",
    "        prob_adj = z @ z.t()\n",
    "        # 得到预测的边列表\n",
    "        return (prob_adj>0).nonzero(as_tuple=False).t()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "边预测神经网络预测"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [],
   "source": [
    "# 定义单个epoch训练过程\n",
    "# 每个epoch的训练过程都进行训练集负样本采样，采样到的负样本数量与正样本数量相同\n",
    "# 不同epoch中采样的样本不同，实现正负样本类别数量平衡，也增加了负样本多样性\n",
    "\n",
    "# 生成完整训练集的标签\n",
    "\n",
    "def get_link_labels(pos_edge_index,neg_edge_index):\n",
    "    num_links = pos_edge_index.size(1) + neg_edge_index.size(1)\n",
    "    link_labels = torch.zeros(num_links,dtype=torch.float)\n",
    "    link_labels[:pos_edge_index.size(1)]=1.\n",
    "    return link_labels\n",
    "\n",
    "# 当RandomLinkSplit的参数add_negative_train_samples=False时\n",
    "def train(train_data,val_data,model,optimizer,criterion):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 对训练集中不存在边的节点对进行采样\n",
    "    # 传递train_data.edge_label_index为参数，只对训练集中不存在边的节点对采样\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=train_data.edge_index,\n",
    "        num_nodes=train_data.num_nodes,\n",
    "        num_neg_samples=train_data.edge_label_index.size(1),method='sparse')\n",
    "\n",
    "    edge_label_index = torch.cat(\n",
    "        [train_data.edge_label_index,neg_edge_index],\n",
    "        dim=-1\n",
    "    )\n",
    "    edge_label = torch.cat([\n",
    "        train_data.edge_label,\n",
    "        train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "    ], dim=0)\n",
    "\n",
    "    # 训练阶段，只使用训练集正样本边\n",
    "    # edge_weight也应该是mask后的\n",
    "    z = model.encode(train_data.x.float(),train_data.edge_index,train_data.edge_weight.float())\n",
    "    # z = model.encode(train_data.x.float(),train_data.edge_index)\n",
    "\n",
    "    link_logits = model.decode(z,edge_label_index)\n",
    "    # link_labels = get_link_labels(train_data.edge_label_index,neg_edge_index).to(train_data.x.device)\n",
    "    # loss = criterion(link_logits,link_labels)\n",
    "    loss = criterion(link_logits,edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    val_auc = eval_link_predictor(model,val_data)\n",
    "\n",
    "    return loss,val_auc\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_link_predictor(model,val_data):\n",
    "    model.eval()\n",
    "    z = model.encode(val_data.x.float(),val_data.edge_index,val_data.edge_weight.float())\n",
    "    # z = model.encode(val_data.x.float(),val_data.edge_index)\n",
    "    out = model.decode(z,val_data.edge_label_index).view(-1).sigmoid()\n",
    "\n",
    "    return roc_auc_score(val_data.edge_label.cpu(),out.cpu())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2708, 1433], edge_index=[2, 82356], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], edge_weight=[82356], edge_label=[41178], edge_label_index=[2, 41178])\n",
      "Data(x=[2708, 1433], edge_index=[2, 82356], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], edge_weight=[82356], edge_label=[4844], edge_label_index=[2, 4844])\n",
      "Data(x=[2708, 1433], edge_index=[2, 87200], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], edge_weight=[87200], edge_label=[9688], edge_label_index=[2, 9688])\n",
      "Epoch:001, Loss:0.6931, Val:0.7402\n",
      "Epoch:002, Loss:0.6887, Val:0.7243\n",
      "Epoch:003, Loss:0.6813, Val:0.7696\n",
      "Epoch:004, Loss:0.6715, Val:0.7971\n",
      "Epoch:005, Loss:0.6576, Val:0.8048\n",
      "Epoch:006, Loss:0.6376, Val:0.8087\n",
      "Epoch:007, Loss:0.6141, Val:0.8373\n",
      "Epoch:008, Loss:0.5865, Val:0.8533\n",
      "Epoch:009, Loss:0.5629, Val:0.8501\n",
      "Epoch:010, Loss:0.5464, Val:0.8426\n",
      "Epoch:011, Loss:0.5450, Val:0.8504\n",
      "Epoch:012, Loss:0.5512, Val:0.8398\n",
      "Epoch:013, Loss:0.5557, Val:0.8513\n",
      "Epoch:014, Loss:0.5497, Val:0.8523\n",
      "Epoch:015, Loss:0.5434, Val:0.8473\n",
      "Epoch:016, Loss:0.5373, Val:0.8506\n",
      "Epoch:017, Loss:0.5312, Val:0.8594\n",
      "Epoch:018, Loss:0.5304, Val:0.8635\n",
      "Epoch:019, Loss:0.5312, Val:0.8642\n",
      "Epoch:020, Loss:0.5329, Val:0.8644\n",
      "Epoch:021, Loss:0.5311, Val:0.8667\n",
      "Epoch:022, Loss:0.5311, Val:0.8684\n",
      "Epoch:023, Loss:0.5287, Val:0.8687\n",
      "Epoch:024, Loss:0.5270, Val:0.8667\n",
      "Epoch:025, Loss:0.5259, Val:0.8633\n",
      "Epoch:026, Loss:0.5252, Val:0.8653\n",
      "Epoch:027, Loss:0.5234, Val:0.8674\n",
      "Epoch:028, Loss:0.5246, Val:0.8659\n",
      "Epoch:029, Loss:0.5226, Val:0.8645\n",
      "Epoch:030, Loss:0.5246, Val:0.8669\n",
      "Epoch:031, Loss:0.5202, Val:0.8724\n",
      "Epoch:032, Loss:0.5192, Val:0.8757\n",
      "Epoch:033, Loss:0.5172, Val:0.8776\n",
      "Epoch:034, Loss:0.5159, Val:0.8825\n",
      "Epoch:035, Loss:0.5145, Val:0.8898\n",
      "Epoch:036, Loss:0.5100, Val:0.8959\n",
      "Epoch:037, Loss:0.5080, Val:0.9008\n",
      "Epoch:038, Loss:0.5031, Val:0.9058\n",
      "Epoch:039, Loss:0.5002, Val:0.9120\n",
      "Epoch:040, Loss:0.4910, Val:0.9169\n",
      "Epoch:041, Loss:0.4889, Val:0.9197\n",
      "Epoch:042, Loss:0.4843, Val:0.9205\n",
      "Epoch:043, Loss:0.4827, Val:0.9221\n",
      "Epoch:044, Loss:0.4784, Val:0.9224\n",
      "Epoch:045, Loss:0.4831, Val:0.9209\n",
      "Epoch:046, Loss:0.4809, Val:0.9200\n",
      "Epoch:047, Loss:0.4832, Val:0.9221\n",
      "Epoch:048, Loss:0.4829, Val:0.9238\n",
      "Epoch:049, Loss:0.4774, Val:0.9250\n",
      "Epoch:050, Loss:0.4780, Val:0.9261\n",
      "Epoch:051, Loss:0.4759, Val:0.9279\n",
      "Epoch:052, Loss:0.4744, Val:0.9294\n",
      "Epoch:053, Loss:0.4731, Val:0.9304\n",
      "Epoch:054, Loss:0.4742, Val:0.9310\n",
      "Epoch:055, Loss:0.4744, Val:0.9316\n",
      "Epoch:056, Loss:0.4748, Val:0.9325\n",
      "Epoch:057, Loss:0.4714, Val:0.9336\n",
      "Epoch:058, Loss:0.4709, Val:0.9344\n",
      "Epoch:059, Loss:0.4710, Val:0.9354\n",
      "Epoch:060, Loss:0.4662, Val:0.9364\n",
      "Epoch:061, Loss:0.4663, Val:0.9378\n",
      "Epoch:062, Loss:0.4632, Val:0.9392\n",
      "Epoch:063, Loss:0.4642, Val:0.9404\n",
      "Epoch:064, Loss:0.4655, Val:0.9414\n",
      "Epoch:065, Loss:0.4624, Val:0.9432\n",
      "Epoch:066, Loss:0.4592, Val:0.9456\n",
      "Epoch:067, Loss:0.4566, Val:0.9473\n",
      "Epoch:068, Loss:0.4548, Val:0.9482\n",
      "Epoch:069, Loss:0.4547, Val:0.9490\n",
      "Epoch:070, Loss:0.4546, Val:0.9497\n",
      "Epoch:071, Loss:0.4562, Val:0.9495\n",
      "Epoch:072, Loss:0.4554, Val:0.9490\n",
      "Epoch:073, Loss:0.4546, Val:0.9491\n",
      "Epoch:074, Loss:0.4529, Val:0.9495\n",
      "Epoch:075, Loss:0.4553, Val:0.9497\n",
      "Epoch:076, Loss:0.4520, Val:0.9506\n",
      "Epoch:077, Loss:0.4527, Val:0.9511\n",
      "Epoch:078, Loss:0.4500, Val:0.9517\n",
      "Epoch:079, Loss:0.4494, Val:0.9521\n",
      "Epoch:080, Loss:0.4495, Val:0.9525\n",
      "Epoch:081, Loss:0.4473, Val:0.9525\n",
      "Epoch:082, Loss:0.4483, Val:0.9525\n",
      "Epoch:083, Loss:0.4498, Val:0.9524\n",
      "Epoch:084, Loss:0.4486, Val:0.9525\n",
      "Epoch:085, Loss:0.4479, Val:0.9529\n",
      "Epoch:086, Loss:0.4488, Val:0.9531\n",
      "Epoch:087, Loss:0.4480, Val:0.9531\n",
      "Epoch:088, Loss:0.4473, Val:0.9534\n",
      "Epoch:089, Loss:0.4442, Val:0.9538\n",
      "Epoch:090, Loss:0.4446, Val:0.9538\n",
      "Epoch:091, Loss:0.4486, Val:0.9536\n",
      "Epoch:092, Loss:0.4504, Val:0.9538\n",
      "Epoch:093, Loss:0.4478, Val:0.9541\n",
      "Epoch:094, Loss:0.4465, Val:0.9540\n",
      "Epoch:095, Loss:0.4469, Val:0.9539\n",
      "Epoch:096, Loss:0.4464, Val:0.9544\n",
      "Epoch:097, Loss:0.4446, Val:0.9547\n",
      "Epoch:098, Loss:0.4441, Val:0.9544\n",
      "Epoch:099, Loss:0.4439, Val:0.9548\n",
      "Epoch:100, Loss:0.4456, Val:0.9549\n",
      "Test::0.9539\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    dataset = 'Cora'\n",
    "    dataset = Planetoid('dataset','Cora',transform=T.NormalizeFeatures())\n",
    "    data = dataset[0]\n",
    "\n",
    "    # 加入mam\n",
    "    # 使用MAM\n",
    "    adj = data.edge_index\n",
    "    adj = torch_geometric.utils.to_scipy_sparse_matrix(data.edge_index)\n",
    "    mam = mcmo.build_motif_adjacency_matrix(adj,motif_name='M13',motif_type='func',mam_method='sparse',mam_weight_type='product')\n",
    "    # 加上原邻接矩阵与边权重\n",
    "    inte_adj = adj + mam\n",
    "    mam_edge_index,mam_edge_weight = torch_geometric.utils.from_scipy_sparse_matrix(inte_adj)\n",
    "    data.edge_index = mam_edge_index\n",
    "    data.edge_weight = mam_edge_weight\n",
    "\n",
    "    # 对边集进行分割\n",
    "    split = T.RandomLinkSplit(is_undirected=True,add_negative_train_samples=False,num_val=0.05,num_test=0.1,neg_sampling_ratio=1.0)\n",
    "    train_data,val_data,test_data = split(data)\n",
    "    train_data = train_data.to(device)\n",
    "    val_data = val_data.to(device)\n",
    "    test_data = test_data.to(device)\n",
    "    print(train_data)\n",
    "    print(val_data)\n",
    "    print(test_data)\n",
    "\n",
    "    model = Net(dataset.num_features,64).to(device)\n",
    "    model = model.float()\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(),lr=0.01)\n",
    "    criterion = F.binary_cross_entropy_with_logits\n",
    "    # criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    best_val_auc = 0\n",
    "    for epoch in range(1,101):\n",
    "        loss,val_auc = train(train_data,val_data,model,optimizer,criterion)\n",
    "        if val_auc > best_val_auc:\n",
    "            best_val_auc = val_auc\n",
    "        print(f'Epoch:{epoch:03d}, Loss:{loss:.4f}, Val:{val_auc:.4f}')\n",
    "\n",
    "\n",
    "    test_auc = eval_link_predictor(model,test_data)\n",
    "    print(f'Test::{test_auc:.4f}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
